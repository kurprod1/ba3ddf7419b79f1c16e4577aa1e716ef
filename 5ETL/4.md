# Study Case: Simple ETL with PySpark

Pada bagian ini, kami akan memberikan sebuah study case bagaimana proses ETL dijalankan pada PySpark.

# Initiation

Kita mulai dengan membuat atau mengunduh file dataset yang akan kita extract, transform dan load. Biasanya dataset ini dapat diperoleh di website bernama [kaggle](http://kaggle.com/). Disini kita disediakan banyak sekali data data yang tujukan untuk keperluan riset dan edukasi.

Kita download dataset dari link

[https://www.kaggle.com/abiyyuhrusin/ebay-kleinanzeigen-car](https://www.kaggle.com/abiyyuhrusin/ebay-kleinanzeigen-car)

atau alternatif berikut

[https://gist.github.com/sdcilsy/e28c99ba7ec24e7fff91848d23f72441](https://gist.github.com/sdcilsy/e28c99ba7ec24e7fff91848d23f72441)

![https://lh6.googleusercontent.com/urWN6A8nSRfadNLS9BrB4ya4xWwiiRe0E9YBx7ytovYI3c24oMsJwvCsfOntiwL_fELP7SPFZ3J6C-LE0H8ywcSTT9ZlGgjrAhtstghkBkUlwb5RsmhCxSiNuuqN8eFSJnsd17-eyEJpv460G1zBLA](https://lh6.googleusercontent.com/urWN6A8nSRfadNLS9BrB4ya4xWwiiRe0E9YBx7ytovYI3c24oMsJwvCsfOntiwL_fELP7SPFZ3J6C-LE0H8ywcSTT9ZlGgjrAhtstghkBkUlwb5RsmhCxSiNuuqN8eFSJnsd17-eyEJpv460G1zBLA)

Lalu kita simpan di direktori **/home/cilsy/praktikum/etl** jika di linux. Lalu pada direktori yang sama, kita eksekusi perintah jupyter-notebook untuk menjalankan notebook.

```bash
jupyter-notebook
```

Outputnya akan seperti ini :

![https://lh5.googleusercontent.com/LXgQBktn57K_scU2GR-patx3UJSAM86Sqb1aIeW8DQo2G1cWzxQt__gXlITmm_gGdOUUgn0ai-nFaF9n8ziuXBrehoP3FSp0i7LIE0yc6o8rcqF8wRB2NVWYS_C1kQVEjtsAGVN9w8QAHPr1N-AUMA](https://lh5.googleusercontent.com/LXgQBktn57K_scU2GR-patx3UJSAM86Sqb1aIeW8DQo2G1cWzxQt__gXlITmm_gGdOUUgn0ai-nFaF9n8ziuXBrehoP3FSp0i7LIE0yc6o8rcqF8wRB2NVWYS_C1kQVEjtsAGVN9w8QAHPr1N-AUMA)

Secara otomatis, kita akan dibawa ke tab pada browser. Ini adalah inisiasi dari penggunaan notebook. Atau jika tidak, maka klik link yang ada pada terminal tersebut.

Setelah notebook terbuka, kita akan melihat tampilan seperti ini

![https://lh6.googleusercontent.com/_TLDaJ4aWiQuF7zLN6fkUqySu9rkjegAJEMmfosMBXFCzRCXfzxAtvoV0d2vYOaUzqX_UFdDYfjalzU-RsC9EagKrYwsWqZasatxZuAIu14GkHRgSddcaOErKxY4RatGk3N6-hp6E46mMq5dDmyb7w](https://lh6.googleusercontent.com/_TLDaJ4aWiQuF7zLN6fkUqySu9rkjegAJEMmfosMBXFCzRCXfzxAtvoV0d2vYOaUzqX_UFdDYfjalzU-RsC9EagKrYwsWqZasatxZuAIu14GkHRgSddcaOErKxY4RatGk3N6-hp6E46mMq5dDmyb7w)

Ya! itu adalah data yang sudah kita download dari website kaggle. Selanjutnya kita buat notebook dengan cara mengeklik tombol new yang berada di kanan atas, lalu pilih versi python yang terinstall.

![https://lh6.googleusercontent.com/Za0V7ujyLVW7K2UlQKR0nykp2RVB1iEw9nkFzWTugSz-HbJPG-_UOLGS5j2shYFgk4QC5emXEcLGGi3yQi2XLvXeKC3zCmjPsS5SAPBJNtm4oq0E2rFxmSvqQ1M7VPBJSt_ELIGHmkexk6ZxiC3N2Q](https://lh6.googleusercontent.com/Za0V7ujyLVW7K2UlQKR0nykp2RVB1iEw9nkFzWTugSz-HbJPG-_UOLGS5j2shYFgk4QC5emXEcLGGi3yQi2XLvXeKC3zCmjPsS5SAPBJNtm4oq0E2rFxmSvqQ1M7VPBJSt_ELIGHmkexk6ZxiC3N2Q)

Setelah itu, akan muncul tab baru dimana kita bisa ngoding untuk melakukan ETL dengan PySpark.

Disini, kita bisa mengisikan nama dari notebook kita, dengan cara mengeklik tulisan Untitled seperti berikut.

![https://lh3.googleusercontent.com/MyRIBiq6fmd5SSgp0f83abHnC_0WEGwuazVGypb1pX1NwRTaA6ghbGU5LLIAq5AZ7kg-pdTGmfU1PztxzDoQWnpvellEs9qm_l5xvngAV0Bgl7Dtk_m1wHhKxBGXAfEjEiHHmWdhVn8WYBavl7U_7Q](https://lh3.googleusercontent.com/MyRIBiq6fmd5SSgp0f83abHnC_0WEGwuazVGypb1pX1NwRTaA6ghbGU5LLIAq5AZ7kg-pdTGmfU1PztxzDoQWnpvellEs9qm_l5xvngAV0Bgl7Dtk_m1wHhKxBGXAfEjEiHHmWdhVn8WYBavl7U_7Q)

Jika sudah, yang pertama kita masukan kedalam code adalah memanggil library yang diperlukan. Dalam kasus ini, kita perlu memanggil library PySpark agar python dapat berkomunikasi dengan Spark, pandas untuk mengolah data, dan psycopg2 untuk berkomunikasi dengan postgres.

Kita masukan code ini kedalam cell lalu cek dengan menekan kombinasi Ctrl+Enter atau Ctrl+Alt.

![https://lh5.googleusercontent.com/YVryrrPpT4jiDYXp-C4pjDe62hBAt4ySnOp-ipCBOrI6U7GSwDXCQwESYhSZXA2X1OWz5fkeluKaVAJmXfE1N8jQM0yNpr1bTVf7YPgZolfNe8iJB_aJIH86UIeIIIJxmzD0tXCDE3JmtCZYZIVKpQ](https://lh5.googleusercontent.com/YVryrrPpT4jiDYXp-C4pjDe62hBAt4ySnOp-ipCBOrI6U7GSwDXCQwESYhSZXA2X1OWz5fkeluKaVAJmXfE1N8jQM0yNpr1bTVf7YPgZolfNe8iJB_aJIH86UIeIIIJxmzD0tXCDE3JmtCZYZIVKpQ)

Selanjutnya, kita buat cell baru dengan code berikut agar python dapat berkomunikasi dengan Spark menggunakan SparkSession.

![https://lh4.googleusercontent.com/B0gqkqXgqp-HD_LgcBQl-ffSV64ZvuAVadWhjYOhFo3_WEhTK6M_RecSijhuFnnxjVG-P2HMvSa6iqBSQ9hoMBks6sDZc6gJGqujticEnXzYA1y6N9fV1Xvv3M6Q190RHj05cKjLrSD1Fb1bRJI1cA](https://lh4.googleusercontent.com/B0gqkqXgqp-HD_LgcBQl-ffSV64ZvuAVadWhjYOhFo3_WEhTK6M_RecSijhuFnnxjVG-P2HMvSa6iqBSQ9hoMBks6sDZc6gJGqujticEnXzYA1y6N9fV1Xvv3M6Q190RHj05cKjLrSD1Fb1bRJI1cA)

# **Extract**

Selanjutnya kita masuk ke tahap extract dimana kita akan membaca dataset yang sudah kita download untuk diolah. Seperti biasa, buat cell dibawah untuk memasukan kode berikut. Ingat untuk memasukan nama file yang benar.

![https://lh4.googleusercontent.com/0Yam46ZmDL48yeLAsFElEhsekUWnFdMUQvtXfec_xPJv-7vG1XXpCIir9P80E1z872JvRXgA4kCn1D0YgtXmxlaEHT1aOEjzMWE5ngVcYumGCQlWz5ScAgfLYXw8fTlckZXZdrBKCunp-DofAVyciw](https://lh4.googleusercontent.com/0Yam46ZmDL48yeLAsFElEhsekUWnFdMUQvtXfec_xPJv-7vG1XXpCIir9P80E1z872JvRXgA4kCn1D0YgtXmxlaEHT1aOEjzMWE5ngVcYumGCQlWz5ScAgfLYXw8fTlckZXZdrBKCunp-DofAVyciw)

Dengan menggunakan pandas, kita bisa dengan mudah mengolah dan melihat data yang begitu banyak. Masukan code berikut

![https://lh6.googleusercontent.com/kXepFA30Nm62y-x09Gj_NbCKM4YqTNuc1QOgpLD-QA-v5sIox_Aehbc-Y1J4aeG5AL78Qz6_afl9AtK8tHmg5PqqXZAddCVEUaelv3tMasbsgS1DNodlMca9-jYMqw6O9e3Q4HYVOlja29Zjp2bQLQ](https://lh6.googleusercontent.com/kXepFA30Nm62y-x09Gj_NbCKM4YqTNuc1QOgpLD-QA-v5sIox_Aehbc-Y1J4aeG5AL78Qz6_afl9AtK8tHmg5PqqXZAddCVEUaelv3tMasbsgS1DNodlMca9-jYMqw6O9e3Q4HYVOlja29Zjp2bQLQ)

Untuk mengetahui jumlah baris pada file autos.csv, kita bisa gunakan fungsi count().

![https://lh3.googleusercontent.com/fwq8eUovMO5THByMwUasv1ri-FYNl7mkr5jCk6SQEEq15Xbrcx1Gt5iKIm68V8Aj8cu7MJ7jQR7OKmlIuzGsfMH4YoUaVTTPGVOqcSCHd4Bw8Kiti7qtUxje3NR42GOhyM7IC1J2msSjj3KTZBf_2Q](https://lh3.googleusercontent.com/fwq8eUovMO5THByMwUasv1ri-FYNl7mkr5jCk6SQEEq15Xbrcx1Gt5iKIm68V8Aj8cu7MJ7jQR7OKmlIuzGsfMH4YoUaVTTPGVOqcSCHd4Bw8Kiti7qtUxje3NR42GOhyM7IC1J2msSjj3KTZBf_2Q)

Sangat banyak bukan ? tapi tenang, tugas ini bisa dikerjakan dengan sangat baik oleh spark. Set back, and relax !

Lalu kita lihat tipe data dari masing masing kolom. Kita bisa menggunakan fungsi printSchema().

![https://lh6.googleusercontent.com/FrPAoBGir3l30oQiLeDMboNz6YL46HDQrk0MYl4sVvUabJsn49R7kwJY9nRvFqcYaavdpJpKp301n-10XlhYtptjNir0dmb1zNLcGmWBTYP_rlidz7eaXaiUbnq_uG0OumOc1Fg3qxK--RTfOCzrvQ](https://lh6.googleusercontent.com/FrPAoBGir3l30oQiLeDMboNz6YL46HDQrk0MYl4sVvUabJsn49R7kwJY9nRvFqcYaavdpJpKp301n-10XlhYtptjNir0dmb1zNLcGmWBTYP_rlidz7eaXaiUbnq_uG0OumOc1Fg3qxK--RTfOCzrvQ)

Sampai disini, kita sudah berhasil untuk melakukan Extract data pada spark menggunakan python.

# **Transform**

Lanjut ke tahap selanjutnya yakni transform. Di tahap ini, kita bisa mengubah bentuk dari data kita. Misalnya mengganti tipe data, mengubah value, menghapus kolom dan lainnya.

Sekarang, kita akan menghapus data data yang memiliki nilai value yang hilang. Kita bisa melakukan hal ini dengan menggunkan fungsi dropna().

![https://lh5.googleusercontent.com/cnKwTNAICl1kQFt8NnDXGaKo90mth5JO56OyInzPdWRBcTvarRz3QJxn2HUmFG7-7h1BKrbxF-TJ_yK2BCbzR4wHcZ3UIgOhxFJLoPdT22O0Vv1P_pxczqxcUIQA7cRUgWIqBFds6jZe_rsc6EyTLA](https://lh5.googleusercontent.com/cnKwTNAICl1kQFt8NnDXGaKo90mth5JO56OyInzPdWRBcTvarRz3QJxn2HUmFG7-7h1BKrbxF-TJ_yK2BCbzR4wHcZ3UIgOhxFJLoPdT22O0Vv1P_pxczqxcUIQA7cRUgWIqBFds6jZe_rsc6EyTLA)

Jika kita lihat kembali output yang dihasilkan oleh pandas (lihat gambar dibawah),

![https://lh6.googleusercontent.com/kXepFA30Nm62y-x09Gj_NbCKM4YqTNuc1QOgpLD-QA-v5sIox_Aehbc-Y1J4aeG5AL78Qz6_afl9AtK8tHmg5PqqXZAddCVEUaelv3tMasbsgS1DNodlMca9-jYMqw6O9e3Q4HYVOlja29Zjp2bQLQ](https://lh6.googleusercontent.com/kXepFA30Nm62y-x09Gj_NbCKM4YqTNuc1QOgpLD-QA-v5sIox_Aehbc-Y1J4aeG5AL78Qz6_afl9AtK8tHmg5PqqXZAddCVEUaelv3tMasbsgS1DNodlMca9-jYMqw6O9e3Q4HYVOlja29Zjp2bQLQ)

kolom seller, offerType, dateCrawled, nrOfPictures dan lastSeen tidak terlalu dibutuhkan untuk penelitian selanjutnya. Oleh karena itu, kita bisa menghapus kolom kolom tersebut menggunakan fungsi drop().

![https://lh3.googleusercontent.com/-X3OyilY1LWtNEqHbKubpBtLq1HVKq7A3SJXYG62v9qkWvXzLw8Dpluci8Mix7uWUqgSCBuq748o2xrukdOib0DUvH6eLIAMhI6D_a-soaGI4WJPl24VJguWSw4_jbTV-m70JhrGpIdq2Xub5e1g2Q](https://lh3.googleusercontent.com/-X3OyilY1LWtNEqHbKubpBtLq1HVKq7A3SJXYG62v9qkWvXzLw8Dpluci8Mix7uWUqgSCBuq748o2xrukdOib0DUvH6eLIAMhI6D_a-soaGI4WJPl24VJguWSw4_jbTV-m70JhrGpIdq2Xub5e1g2Q)

Jika diperhatikan seksama, kolom price dan odometer merupakan data yang bisa di hitung aatau integer. Namun pada perintah sebelumnya, kita melihat bahwa semua tipe data kolom tersebut adalah string. Oleh karena itu, kita akan mengubah tipe data dari kolom price dan odometer menjadi integer.

Namun masalahnya adalah masih ada karakter yang tidak memungkinkan untuk diubah ke tipe data integer. Karakter tersebut adalah dollar sign ($), koma (,) dan huruf km. kita harus menyingkirkan karakter karakter itu dulu supaya berhasil mengubahnya menjadi tipe data integer.

Caranya menggunakan fungsi withColumn() untuk mengubah kolom danÂ  regexp_replace untuk mengganti karakter.

![https://lh5.googleusercontent.com/xH1iGAHH2sjuE6NSKrTy3gaY_D87_RH4ttRHMoT5ZaaX44z2lHz2VEETTpYZafGci0jn68MlVCD0LqQfydIgOPlPWHNW28hqkaQA-B1chbwLIEChiT4w8dvQpUOvsysmviMg8HXIJDBIxZBVYSRy_g](https://lh5.googleusercontent.com/xH1iGAHH2sjuE6NSKrTy3gaY_D87_RH4ttRHMoT5ZaaX44z2lHz2VEETTpYZafGci0jn68MlVCD0LqQfydIgOPlPWHNW28hqkaQA-B1chbwLIEChiT4w8dvQpUOvsysmviMg8HXIJDBIxZBVYSRy_g)

Lalu saatnya kita mengubah kolom yang sudah kita transform tadi menjadi integer. Menggunakan fungsi withColumn, kita mengubah kolom lama menjadi baru dan cast untuk mengubah tipe data menjadi integer

![https://lh4.googleusercontent.com/UZZEjIZT5pPn9swxkrLQpnqorDb8aLk2x0NEpUu6hapmjNl0_ezII7102_w6eH28yJW42fDJqlyXCwJmEgJzuEgk7-QDtD4Ji3_ffCpm0UbVVTmRc6t-StMjfJUFH-KozLhripMdGvSfSnI-eO1geQ](https://lh4.googleusercontent.com/UZZEjIZT5pPn9swxkrLQpnqorDb8aLk2x0NEpUu6hapmjNl0_ezII7102_w6eH28yJW42fDJqlyXCwJmEgJzuEgk7-QDtD4Ji3_ffCpm0UbVVTmRc6t-StMjfJUFH-KozLhripMdGvSfSnI-eO1geQ)

Lalu kita buat suatu variable untuk menampung data transformasi yang sudah final.

![https://lh6.googleusercontent.com/PiXkDowQVH2h3kdAKLedG2PWp6sKT28a9VUHmqd67lKXmb5LDgIRA0abVuTmVZM2pTYg49TEzt3-7i3M5_uAz4supUN6XLvflFesXMQC5_nKDCq457kWWcZfy4LbmryyU-qUm7KXlhAtL5PFnCK8jg](https://lh6.googleusercontent.com/PiXkDowQVH2h3kdAKLedG2PWp6sKT28a9VUHmqd67lKXmb5LDgIRA0abVuTmVZM2pTYg49TEzt3-7i3M5_uAz4supUN6XLvflFesXMQC5_nKDCq457kWWcZfy4LbmryyU-qUm7KXlhAtL5PFnCK8jg)

Jumlah row dataset akan berubah.

![https://lh5.googleusercontent.com/rzTy_bAOTVDBiJizssloJw5o3QkMrTm1KeMZZrPEWirz4EEmxnGBlj0CdfFHiYCl0u2BZyp6JDLnkZSeOyLyGgoD5KlA4Pdq40aWMJJvM_NPbuE4V4MsStk2YoNkETPkjBsLq78gTOcggvOdy2JlOA](https://lh5.googleusercontent.com/rzTy_bAOTVDBiJizssloJw5o3QkMrTm1KeMZZrPEWirz4EEmxnGBlj0CdfFHiYCl0u2BZyp6JDLnkZSeOyLyGgoD5KlA4Pdq40aWMJJvM_NPbuE4V4MsStk2YoNkETPkjBsLq78gTOcggvOdy2JlOA)

Selamat ! Sekarang kita sudah memiliki data yang sudah diolah dan siap untuk dimasukan ke database.

# **Load**

Tahap selanjutnya adalah load dimana kita memasukan data ke sebuah data lake atau data warehouse. Ini bertujuan agar data kita bisa dianalisa oleh data analyst.

Sekarang kita akan memasukan data kita ke Postgres. Coba ingat ingat kembali cara agar kita bisa terhubung ke postgres.

Kita menggunakan library psycopg2 untuk terhubung ke postgres. Lalu kita isi akun untuk masuk ke dalam postgres.

![https://lh3.googleusercontent.com/B6fwvsGA7aMLnm6QqKVn2gjiYJCZloUl11jr_MphCxL2sPkTunDH34SZPkfn29dxzxYpZdBl8GMko285eFS9jmHYBPMITthbTUfhz8w_2YWmwsStnq5I1DtsNou9YODezylXKGvd2q7om3yYjpW5ug](https://lh3.googleusercontent.com/B6fwvsGA7aMLnm6QqKVn2gjiYJCZloUl11jr_MphCxL2sPkTunDH34SZPkfn29dxzxYpZdBl8GMko285eFS9jmHYBPMITthbTUfhz8w_2YWmwsStnq5I1DtsNou9YODezylXKGvd2q7om3yYjpW5ug)

Setelah itu, kita buat sebuah kursor agar python dapat melakukan transaksi ke postgres.

![https://lh4.googleusercontent.com/1hYOqVk7p4gVox6AMmAcSrl1TcgoZHf4cSep-1U2LBKPcL8oScyB_7Jl2W82sjSi5ITJipsockpgWe7D29sHj7T6hY3pJy_MPVLbzRb0soe78FqSjsHfOn5dmdgnLyi8VxCbyOIe47xNlhjGfAHJpg](https://lh4.googleusercontent.com/1hYOqVk7p4gVox6AMmAcSrl1TcgoZHf4cSep-1U2LBKPcL8oScyB_7Jl2W82sjSi5ITJipsockpgWe7D29sHj7T6hY3pJy_MPVLbzRb0soe78FqSjsHfOn5dmdgnLyi8VxCbyOIe47xNlhjGfAHJpg)

Setelah itu, kita buat sebuah tabel bernama cars_table dengan kolom kolom yang sesuai dengan data kita.

![https://lh6.googleusercontent.com/LJbYJSPh2iE5khi_GHUaJJ1vnLcbmFFhQDkxv55rhwH5akm-bisB4uM9khi2RDhX0FoHN4lBf6TKfsxBrvuwGTJqGyAiFuK3uLxyvGz64doJQ3N5Ts7RRN_SuvdUtM9wGxejus1RMZ8U_fuTL8JT7w](https://lh6.googleusercontent.com/LJbYJSPh2iE5khi_GHUaJJ1vnLcbmFFhQDkxv55rhwH5akm-bisB4uM9khi2RDhX0FoHN4lBf6TKfsxBrvuwGTJqGyAiFuK3uLxyvGz64doJQ3N5Ts7RRN_SuvdUtM9wGxejus1RMZ8U_fuTL8JT7w)

Setelah itu, kita akan memasukan seluruh data yang sudah kita olah tadi kedalam Postgres. Kita membutuhkan looping agar semua data bisa kita masukan bisa kita masukan.

![https://lh6.googleusercontent.com/tHWrStbcynGGGpO9qyeU3z20zM6i2EL67bv3G-5B3iH1nVbutag0AOLsaN-ObpOm2mmp0u5yUZy4-MfNC8qHhBeopV_7ZbOCv2W0NtMHTmMNHLguKZk0OgZ6MJi7PSOoLfC034KdCVo9KCydeDPW8Q](https://lh6.googleusercontent.com/tHWrStbcynGGGpO9qyeU3z20zM6i2EL67bv3G-5B3iH1nVbutag0AOLsaN-ObpOm2mmp0u5yUZy4-MfNC8qHhBeopV_7ZbOCv2W0NtMHTmMNHLguKZk0OgZ6MJi7PSOoLfC034KdCVo9KCydeDPW8Q)

Saatnya eksekusi untuk memasukan data ke postgres

![https://lh4.googleusercontent.com/9tmADs5VKqpF9ilsv_sEgRs2hIlTNAffEuk4MZqWJYziWglE3CP8Ha8HaaTCtmlerh8ghnBzLuY5943e2hZAwvDoYtrfiv5AlKnjJSPGI8SSlPVUjjyWmjGaG_1rKrVCYq4uhh7MVmTod0rZ8kCtew](https://lh4.googleusercontent.com/9tmADs5VKqpF9ilsv_sEgRs2hIlTNAffEuk4MZqWJYziWglE3CP8Ha8HaaTCtmlerh8ghnBzLuY5943e2hZAwvDoYtrfiv5AlKnjJSPGI8SSlPVUjjyWmjGaG_1rKrVCYq4uhh7MVmTod0rZ8kCtew)

Dan yang terakhir, kita putuskan koneksi antara python ke postgres

![https://lh6.googleusercontent.com/XzdvezIb70WCNQtvHiZQZvlPhz2dHmlsVSOujkCXGhDMixfzoErd8eOcJ_ZK45sl4Ef64V7Jqy29y1iZ3WHAxK35w0klHzDLCZCS85CZmRlKgpw6RXAPxsx4jAKsxg7bzE2_bzzK9AeecaFQyVOoRA](https://lh6.googleusercontent.com/XzdvezIb70WCNQtvHiZQZvlPhz2dHmlsVSOujkCXGhDMixfzoErd8eOcJ_ZK45sl4Ef64V7Jqy29y1iZ3WHAxK35w0klHzDLCZCS85CZmRlKgpw6RXAPxsx4jAKsxg7bzE2_bzzK9AeecaFQyVOoRA)