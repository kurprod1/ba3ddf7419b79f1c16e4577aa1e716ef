# ETL Introduction

ETL merupakan salah satu proses paling penting dalam dunia big data. ETL yang merupakan singkatan dari Extract, Transform, and Load merupakan serangkaian proses untuk melakukan pengumpulan, pengekstrakan, pengolahan, serta pemanfaatan data melalui arsitektur yang telah disusun oleh seorang data engineer.

# Timeline

Kami menyarankan untuk mempelajari topik ini secara mendalam dengan menggunakan timeline sebagai berikut:

[Untitled](ETL%20Introduction%20fff01f98b5074d10af4c36edb007b292/Untitled%20Database%2046a2160ec9ea40ac81a088aa625979bd.csv)

Akan tetapi kami juga menyadari bahwa tempo belajar setiap orang akan berbeda-beda, maka dari itu, kamu bisa menyesuaikan *pace* belajarmu, namun dengan catatan jangan melebihi dari *guideline* waktu yang ditentukan, ya, karena masih banyak hal yang perlu kita pelajari kedepannya.

# **Mendalami Proses Extract**

Tahap pertama dan yang terpenting adalah proses ekstraksi. Bagaimana dari data-data mentah dengan format yang bermacam-macam, berasal dari sumber yang bermacam-macam bisa diambil dan dikumpulkan. Contoh data-data mentah adalah sebagai berikut :

- File-file format CSV dari berbagai sumber, misal dari Google Analitycs, dari Facebook Ads Dashboard, dari file-file excel tim marketing, dari file-file excel tim akuntan, dari database website, dll
- File-file hasil *scrapping* web dan sosial media, biasanya berformat JSON atau XML. Misalnya berupa postingan orang-orang di twitter yang terkait hastag #sepatupria.

File-file hasil ekstraksi ini biasanya disimpan dalam environment *Staging* atau *Data Staging*, yang hanya bisa diakses oleh sesama tim Big Data Engineer saja untuk keperluan proses berikutnya. Belum bisa diakses oleh tim lain. Jika Anda bingung maksud dari ekstraksi ini apa, pokoknya disini adalah proses mengumpulkan data saja. Sesederhana itu.

[https://lh4.googleusercontent.com/ual7UjYTvFGoEPJJAn4QinWIkSS0PSj5nlFKK0HVj00C1a2gu2FiDLlzy-XVurWGFIk8-3pQTVYagF6alzwyrHb3iQJCnIKbRCB7b3gHEQvy4jyCapKHlQFoGa_h-pcZVYOHnNcGmU7jkonSiw](https://lh4.googleusercontent.com/ual7UjYTvFGoEPJJAn4QinWIkSS0PSj5nlFKK0HVj00C1a2gu2FiDLlzy-XVurWGFIk8-3pQTVYagF6alzwyrHb3iQJCnIKbRCB7b3gHEQvy4jyCapKHlQFoGa_h-pcZVYOHnNcGmU7jkonSiw)

Proses ekstraksi ini biasanya akan terus berjalan secara realtime 24/7 untuk bisa mengambil berbagai data baru maupun mengupdate data yang ada.

# **Mendalami Proses Transform**

File-file dari proses ekstraksi akan ditransformasi / dikategorikan / dikelompokkan ke dalam format yang lebih rapi & mudah dibaca agar benar-benar bisa digunakan nantinya. Bentuk Transformasinya akan sangat *variatif* tergantung dari tujuan perusahaan tadi. Hal-hal yang tidak perlu, ya tidak perlu dimasukkan.

Contoh-contoh nya adalah sebagai berikut :

- Hanya menampilkan kolom yang diinginkan, misal ada 30 lebih kolom, tapi yang dibutuhkan hanya kolom Gender, Usia, dan Tempat Tinggal. Maka kolom Hobi, Tempat Tanggal Lahir, dll akan dihilangkan.
- Mengkodekan suatu nilai. Misalnya Pria, Laki-Laki, Men menjadi kode M, dan Wanita, Perempuan menjadi kode F.
- Mengurutkan suatu nilai. Misal mengurutkan usia dari yang termuda hingga tertua.
- Memecah 1 kolom jadi beberapa kolom. Misal ada 1 kolom berisi “31;Male;Surabaya”. Ini bisa dipecah jadi 1 kolom berisi 31, 1 kolom berisi Male, 1 kolom berisi Surabaya.

Hasil transformasi ini akan dikelompokkan menjadi berbagai *set* data yang rapi. Misal ada set data pembeli 5 tahun terakhir, ada set data penjual 5 tahun terakhir, hingga ada set data traffic web 5 tahun terakhir.

[https://lh6.googleusercontent.com/PZlNo_rUGPEQkZb8K-L9PRnWs1NQgPpjeO03yGVZhl1Xb0HeGyyuSVS-ik4p9LWZ2i0OOm7oMw7h2XMaxogaltKjYFEv9JWkenLRmWltNy5eLosjHpV4MWJ_gWZ7VIa7f6wCChx5AWHXRFAaXA](https://lh6.googleusercontent.com/PZlNo_rUGPEQkZb8K-L9PRnWs1NQgPpjeO03yGVZhl1Xb0HeGyyuSVS-ik4p9LWZ2i0OOm7oMw7h2XMaxogaltKjYFEv9JWkenLRmWltNy5eLosjHpV4MWJ_gWZ7VIa7f6wCChx5AWHXRFAaXA)

Agar mempunyai gambaran seperti apa hasil jadi dari sebuah *set data*, unduhlah contoh set data dari daftar korban penumpang titanic berikut : [https://gist.github.com/michhar/2dfd2de0d4f8727f873422c5d959fff5](https://gist.github.com/michhar/2dfd2de0d4f8727f873422c5d959fff5)

# **Mendalami Proses Load**

Berbagai set data yang sudah jadi diatas, akan disimpan di Data Warehouse. Data ini bisa diakses oleh tim lainnya secara publik untuk diolah kembali lebih lanjut.

[https://lh5.googleusercontent.com/y2nPoLoJitjTPaXyaJRQCASMg1A_LNudOiG84okQfee-M0Q-Sqxy-S87rv6hYx_wzlcnZORRANrNJlosEJfwpT7xy8jICpZUX9rSenXB4NASdnLoLSpLruB2xMZOKbGnScitbgWGk3I7eng5gg](https://lh5.googleusercontent.com/y2nPoLoJitjTPaXyaJRQCASMg1A_LNudOiG84okQfee-M0Q-Sqxy-S87rv6hYx_wzlcnZORRANrNJlosEJfwpT7xy8jICpZUX9rSenXB4NASdnLoLSpLruB2xMZOKbGnScitbgWGk3I7eng5gg)

Data Warehouse ini intinya mirip seperti *database* biasa saja, namun karena isiannya yang super besar maka lebih sering disebut Data Warehouse. Dan proses penyimpanan data ke Data Warehouse ini biasanya terjadi 1 kali per hari, entah itu untuk memasukkan data baru atau mengupdate data yang sudah ada.

Pekerjaan Big Data Engineer berakhir sampai sini. Mereka hanya memastikan data-data bagus sudah disimpan rapi di Data Warehouse. Lalu siapa yang akan mengolah data-data ini menjadi suatu rekomendasi untuk perusahaan yang bernilai lebih baik ? Mereka adalah para **Data Scientist**.

Data Scientist akan mengolah data-data tersebut untuk mendapatkan insight-insight berharga. Misalnya jika kita kaitkan dengan kasus perusahaan sepatu sebelumnya, Data Scientist bisa menghasilkan bentuk analisa-analisa seperti berikut :

- Muncul hasil analisa misalnya produk yang paling laris adalah Sepatu Boots.
- Yang paling banyak membeli sepatu boots adalah Pria umur 30-35 tahun.
- 60% pembeli pria adalah yang 1-2x posting hal-hal terkait Motor Gede di Twitter mereka.
- Setiap membeli Sepatu Boots, 50% dari mereka juga membeli produk kaos kaki hitam.
- Yang paling tidak laku adalah Sepatu High Heels Wanita.
- Traffic web paling besar adalah jam 20.00 – 22.00 weekdays.

Hasil akhir analisa diatas disajikan dalam bentuk dashboard atau visualisasi. Berikut adalah salah satu contoh hasil akhir data yang sudah berbentuk visual ( contoh analisa top 10 aktor yang punya pendapatan tertinggi di dunia ) :

[https://lh6.googleusercontent.com/s8uvtP6HO2k4qewJyky5VpplZ8oCzZZjmdOp6zdaSz0BSSldSMTZmssmt8-0i4v5EZaC9v-Yq34As8RFV3EX2Irimo31dlfGbCBSn-PEzTECe0gJ95_R8r1VgTTxWE2gUkDf-2kHLIQ8dl19Aw](https://lh6.googleusercontent.com/s8uvtP6HO2k4qewJyky5VpplZ8oCzZZjmdOp6zdaSz0BSSldSMTZmssmt8-0i4v5EZaC9v-Yq34As8RFV3EX2Irimo31dlfGbCBSn-PEzTECe0gJ95_R8r1VgTTxWE2gUkDf-2kHLIQ8dl19Aw)