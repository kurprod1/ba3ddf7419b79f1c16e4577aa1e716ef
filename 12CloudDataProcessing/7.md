# Study Case dan Gambaran Best Practice Arsitektur Big Data

# **Gambaran Best Practice Arsitektur Big Data di Cloud - Study Case 1**

[Arsitektur Google Cloud untuk Time Series Analysis](https://lh4.googleusercontent.com/qa5iRa2a2rKCqRe_JmrQkGx7ZP55YdIO5x8lizwzOH57CSbuKrSnx4cglKAhc_jeyOauwQn-7IkRGICLtRnBhtDDiWt10UffR27r7tan5UYkElKWWLPEoT7BGSPoaBOcHW9QkI-X7KT2UtNR7KqqNg)

Arsitektur Google Cloud untuk Time Series Analysis

Penjelasan :

Data Source ada 2 yaitu Cloud Storage(Batch) dan Cloud Pub Sub(Streaming). Dari 2 data source tersebut di olah di Cloud Data Flow. Pengolahan data meliputi membersihkan data, aggregrasi, dan join. Setelah selesai dilakukan pengolahan data maka disimpan di Bigquery, Bigtable dan Cloud Storage. Kemudian data yang disimpan tersebut bisa dilakukan proses pengolahan data lebih lanjut misal untuk membuat machine learning model menggunakan Cloud ML, membuat analisa data menggunakan Cloud Datalab atau pengolahan data menggunakan spark di cloud Dataproc.

# **Gambaran best practice arsitektur Big Data di Cloud - Study Case 2**

[Migrasi Oracle Data Warehouse ke Google Cloud Bigquery](https://lh6.googleusercontent.com/gbRh07yftZ2E-GH6Uplq3NVGtGJiadY46Rz4VDBX3Vq-4xAuVmMp99za-QzYAZiiaCdAEOZ8Xfz_XNxXcHs25htKK8DeqSVKvjXAY4tr8RfirqSy27jQNfJ1vbPE1u7m-xuxtN5unekkIYN9BGI-Tw)

Migrasi Oracle Data Warehouse ke Google Cloud Bigquery

Penjelasan :

Sumber Data Oracle Data Warehouse di upload ke Cloud Storage kemudian dilakukan pengolahan data meliputi membersihkan data, aggregrasi, dan join. Setelah selesai dilakukan pengolahan data maka bisa menjalankan job secara manual atau terjadwal dimana job tersebut dijalankan secara background oleh Dataflow. Setelah job berjalan oleh Dataflow, data tersebut di simpan di BigQuery. Data dari Bigquery bisa dibuat dashboard atau grafik menggunakan BI tools seperti Google Data Studio atau BI tools lain.

# **Gambaran best practice arsitektur Big Data di Cloud - study case 3**

[Arsitektur Pengolahan Data secara Batch menggunakan Hadoop di Google Cloud](https://lh3.googleusercontent.com/_ZoPQR9c5lw-znZQTSCIQy4Wd4tMAAe6wpaREK4e3QG0D8zeuAhkpJOa-Al_6MM4pLB7rOh_vDYrDNjPnX291y2x84WgfrJ3BMWeLDn-28GfCC591DXTbVJtt_gAp-K4RH-Lx4htZg6k4PGuHA0L5g)

Arsitektur Pengolahan Data secara Batch menggunakan Hadoop di Google Cloud

Penjelasan :

Data dari Cloud Storage dilakukan pengolahan menggunakan Cloud Dataproc atau Cloud Dataprep atau Cloud Dataflow. Kemudian hasil pengolahan tersebut, data disimpan ke cloud storage dengan tipe file parquet, orc dan avro. Kemudian data2 tersebut dilakukan proses pengolahan dengan menjalankan Apache Spark job di Cloud Dataproc. Hasil dari pengolahan tersebut dibagikan ke user.