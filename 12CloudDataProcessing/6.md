# Hadoop Cluster on GCP

Di Materi sebelumnya sudah dijelaskan bahwa install hadoop di cloud salah satunya menggunakan servis GCP yaitu dataproc mudah sekali dan tidak perlu skill khusus. Langkah - langkah nya yaitu :

• Klik Navigation Menu

![https://lh6.googleusercontent.com/fMPy2gf3KrkO8qPvir7c655QBW74E7zvOCTlNosT2p-XtKDqdsECAUhoJWr0PDfSE0ZECHLj-2Gp5qC8t4zlwLNuojfe28BYMeVNv9ydg9gna-WQ_mk2knUGM1wMyDtH5WT44lA6PHnUjomYz3EyJw](https://lh6.googleusercontent.com/fMPy2gf3KrkO8qPvir7c655QBW74E7zvOCTlNosT2p-XtKDqdsECAUhoJWr0PDfSE0ZECHLj-2Gp5qC8t4zlwLNuojfe28BYMeVNv9ydg9gna-WQ_mk2knUGM1wMyDtH5WT44lA6PHnUjomYz3EyJw)

• Pilih Dataproc → Cluster

![https://lh4.googleusercontent.com/lPIxw6e7SRgVrG3d7h2jslNiOsEybromE53MMkDQrCp8rR1ybr1dhQRK-nVfSTPno4wbRXNA4zr5QnhhvMLm2sb0NRsC3qbRHJiOA5Kjs2zTei7cMbgAAdlPuurvV-h3-db5F8-B8XUwYs_4kV2AZA](https://lh4.googleusercontent.com/lPIxw6e7SRgVrG3d7h2jslNiOsEybromE53MMkDQrCp8rR1ybr1dhQRK-nVfSTPno4wbRXNA4zr5QnhhvMLm2sb0NRsC3qbRHJiOA5Kjs2zTei7cMbgAAdlPuurvV-h3-db5F8-B8XUwYs_4kV2AZA)

• Klik Create Cluster

• Input name yang unik

• Pilih region dan zone

• Pilih Cluster Mode standard (1 Master, N Workers)

• Di Master Node machine configuration, biarkan default..

![https://lh3.googleusercontent.com/zoJZc4QUsuXT8EOqViJCgbgrgOCy_Z0b-fTJFpHYzeiyFVzsijpp6_5VAfYl8EkJBRWQ2qwZLddTb4RC2ZunuUPneV4f3qbzR49kDFEm39eoLjcjvirmv_fTPy5WVNemaoIB2azVqGc_sflZgmbM_Q](https://lh3.googleusercontent.com/zoJZc4QUsuXT8EOqViJCgbgrgOCy_Z0b-fTJFpHYzeiyFVzsijpp6_5VAfYl8EkJBRWQ2qwZLddTb4RC2ZunuUPneV4f3qbzR49kDFEm39eoLjcjvirmv_fTPy5WVNemaoIB2azVqGc_sflZgmbM_Q)

• Di worker node machine configuration, pilih machine type n1-standard-2 dan biarkan yang lain default kemudian klik Create.

![https://lh5.googleusercontent.com/nZKLzuaZvUDErIugJDGePTZBypfbADq0-1OHKaTuk6ZRQ7aQ2iYqA2BODHpjcRz7OOFrVolpZkqXaJds2b75O9aVgfN_0uctmkFASVZWyCMb4jM36zHK0fnIa5iACF-Omc3OEcA6La8iHffLsxpWZA](https://lh5.googleusercontent.com/nZKLzuaZvUDErIugJDGePTZBypfbADq0-1OHKaTuk6ZRQ7aQ2iYqA2BODHpjcRz7OOFrVolpZkqXaJds2b75O9aVgfN_0uctmkFASVZWyCMb4jM36zHK0fnIa5iACF-Omc3OEcA6La8iHffLsxpWZA)

• Tunggu sampai selesai kira-kira 1 menit. Jika sudah selesai akan muncul seperti di bawah ini.

![https://lh5.googleusercontent.com/lBO9rpHtto6saZpyHblg5uyvolTVr2OZKnP0xFeEHgmt3hFiLzghGgcVQhXJtiXSZ3GfteLKkeD9Ke42syCnkiL6C_L8Vjv3Vg4fpUDUX7hyGpEOOgBXQRdXXHM7wacTLnWwPPLCnaujYAulhAEv2g](https://lh5.googleusercontent.com/lBO9rpHtto6saZpyHblg5uyvolTVr2OZKnP0xFeEHgmt3hFiLzghGgcVQhXJtiXSZ3GfteLKkeD9Ke42syCnkiL6C_L8Vjv3Vg4fpUDUX7hyGpEOOgBXQRdXXHM7wacTLnWwPPLCnaujYAulhAEv2g)

• Jika kalian ke compute engine maka ada 3 vm yang sedang running. Vm tersebut adalah 1 master node dan 2 worker node. Jika kalian mau masuk ke masing2 node bisa klik SSH.

![https://lh5.googleusercontent.com/lk0ZVgO3lqc5Qt1XlzA_D38q0mFN5eFTj7QFfiChIf70_4sVUX9Mgxlof6SenR67ROvUJ5Umx3SRMLxY_P490n5zuqOabSbmsSs-TnKHjNKrHgyOuGf5MpPUOC0j_uBkYOAAvniWKXaEQphNMbYI0w](https://lh5.googleusercontent.com/lk0ZVgO3lqc5Qt1XlzA_D38q0mFN5eFTj7QFfiChIf70_4sVUX9Mgxlof6SenR67ROvUJ5Umx3SRMLxY_P490n5zuqOabSbmsSs-TnKHjNKrHgyOuGf5MpPUOC0j_uBkYOAAvniWKXaEQphNMbYI0w)

• Di cluster dataproc sudah ada hadoop ecosystem yang terdiri dari Apache Hadoop, Apache Spark, Apache Hive.